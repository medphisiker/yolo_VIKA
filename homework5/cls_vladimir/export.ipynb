{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a99eb5a8-1513-4cbb-887e-e790bd0dd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632734ec-7dc1-457b-96aa-19201828cfef",
   "metadata": {},
   "source": [
    "## Base eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46fb97b-bcd2-41c2-877e-0576b9f5ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b1b109-ed61-4213-a9d5-b9adfa767dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/usr/src/ultralytics/runs/classify/train/weights/best.pt'\n",
    "model = YOLO(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76dd5c09-fe7e-424f-9900-e82338e9e85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA A100 80GB PCIe, 81093MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36197386 parameters, 0 gradients, 98.7 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /usr/src/datasets/imagewoof/train... found 9025 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /usr/src/datasets/imagewoof/val... found 3929 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /usr/src/datasets/imagewoof/val... 3929 images, 0 corrupt: 100%|██████████| 3929/3929 [00:00<?, ?it/s]\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 246/246 [00:03<00:00, 81.10it/s]\n",
      "                   all      0.925      0.995\n",
      "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/val8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data='imagewoof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd623ac-d6e8-43b3-9c97-2edec6d2769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 accuracy 0.925\n",
      "Top1 accuracy 0.995\n",
      "preprocess speed 0.101 ms\n",
      "inference speed 0.446 ms\n",
      "loss speed 0.001 ms\n",
      "postprocess speed 0.001 ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Top1 accuracy {metrics.top1:.3f}')\n",
    "print(f'Top1 accuracy {metrics.top5:.3f}')\n",
    "for stage, time in metrics.speed.items():\n",
    "    print(f'{stage} speed {time:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81a75c90-cf06-430c-b178-1a2e7af73200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.2 Мб\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(\"/usr/src/ultralytics/runs/classify/train/weights/best.pt\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4fe41-0b26-4f16-92d0-ed248cdd25ae",
   "metadata": {},
   "source": [
    "## ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3ebefc-d5c7-488c-a7a9-72ecb1003024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CPU (Intel Xeon Gold 6248 2.50GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/usr/src/ultralytics/runs/classify/train/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 10) (69.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.8s, saved as '/usr/src/ultralytics/runs/classify/train/weights/best.onnx' (138.1 MB)\n",
      "\n",
      "Export complete (5.6s)\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/usr/src/ultralytics/runs/classify/train/weights/best.onnx imgsz=224  \n",
      "Validate:        yolo val task=classify model=/usr/src/ultralytics/runs/classify/train/weights/best.onnx imgsz=224 data=imagewoof  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/usr/src/ultralytics/runs/classify/train/weights/best.onnx'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9668a36a-67a1-456c-9247-e7fe46ce670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = YOLO(\"/usr/src/ultralytics/runs/classify/train/weights/best.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc991682-e07f-423f-bb33-ef670db30642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA A100 80GB PCIe, 81093MiB)\n",
      "Loading /usr/src/ultralytics/runs/classify/train/weights/best.onnx for ONNX Runtime inference...\n",
      "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /usr/src/datasets/imagewoof/train... found 9025 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /usr/src/datasets/imagewoof/val... found 3929 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /usr/src/datasets/imagewoof/val... 3929 images, 0 corrupt: 100%|██████████| 3929/3929 [00:00<?, ?it/s]\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 3929/3929 [03:47<00:00, 17.24it/s]\n",
      "                   all      0.925      0.995\n",
      "Speed: 0.0ms preprocess, 48.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/val9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = onnx_model.val(data='imagewoof', imgsz=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45134a82-9d1d-45e7-9073-5c5f3b490cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 accuracy 0.925\n",
      "Top1 accuracy 0.995\n",
      "preprocess speed 0.044 ms\n",
      "inference speed 48.731 ms\n",
      "loss speed 0.018 ms\n",
      "postprocess speed 0.013 ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Top1 accuracy {metrics.top1:.3f}')\n",
    "print(f'Top1 accuracy {metrics.top5:.3f}')\n",
    "for stage, time in metrics.speed.items():\n",
    "    print(f'{stage} speed {time:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fcf9a07-bccb-46dd-bc28-3ae3b449ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38e+02 Мб\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(\"/usr/src/ultralytics/runs/classify/train/weights/best.onnx\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac618c-7d48-4f51-bd2e-44748ff7db6b",
   "metadata": {},
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b0b4a1-4aa5-4e4f-af01-0641b5bf9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA A100 80GB PCIe, 81093MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/usr/src/ultralytics/runs/classify/train/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 10) (69.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting onnxruntime-gpu\n",
      "  Obtaining dependency information for onnxruntime-gpu from https://files.pythonhosted.org/packages/22/aa/f7c78b440e94478f72d2a627ec82be4032b9b8141a2506f2ec7d99645483/onnxruntime_gpu-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnxruntime_gpu-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.23.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (4.24.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.11.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Downloading onnxruntime_gpu-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.16.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 11.7s, installed 1 package: ['onnxruntime-gpu']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 20.1s, saved as '/usr/src/ultralytics/runs/classify/train/weights/best.onnx' (138.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-12:24:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +556, GPU +0, now: CPU 5580, GPU 20854 (MiB)\n",
      "[10/21/2023-12:24:03] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +545, GPU +134, now: CPU 6144, GPU 20988 (MiB)\n",
      "[10/21/2023-12:24:03] [TRT] [I] ----------------------------------------------------------------\n",
      "[10/21/2023-12:24:03] [TRT] [I] Input filename:   /usr/src/ultralytics/runs/classify/train/weights/best.onnx\n",
      "[10/21/2023-12:24:03] [TRT] [I] ONNX IR version:  0.0.8\n",
      "[10/21/2023-12:24:03] [TRT] [I] Opset version:    17\n",
      "[10/21/2023-12:24:03] [TRT] [I] Producer name:    pytorch\n",
      "[10/21/2023-12:24:03] [TRT] [I] Producer version: 2.0.1\n",
      "[10/21/2023-12:24:03] [TRT] [I] Domain:           \n",
      "[10/21/2023-12:24:03] [TRT] [I] Model version:    0\n",
      "[10/21/2023-12:24:03] [TRT] [I] Doc string:       \n",
      "[10/21/2023-12:24:03] [TRT] [I] ----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 224, 224) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 10) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as /usr/src/ultralytics/runs/classify/train/weights/best.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-12:24:03] [TRT] [W] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[10/21/2023-12:24:05] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +32, now: CPU 6283, GPU 21020 (MiB)\n",
      "[10/21/2023-12:24:05] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +34, now: CPU 6284, GPU 21054 (MiB)\n",
      "[10/21/2023-12:24:05] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/21/2023-12:25:21] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.\n",
      "[10/21/2023-12:25:25] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[10/21/2023-12:25:25] [TRT] [I] Total Host Persistent Memory: 149248\n",
      "[10/21/2023-12:25:25] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[10/21/2023-12:25:25] [TRT] [I] Total Scratch Memory: 512\n",
      "[10/21/2023-12:25:25] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB\n",
      "[10/21/2023-12:25:25] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 41.2785ms to assign 15 blocks to 162 nodes requiring 11640856 bytes.\n",
      "[10/21/2023-12:25:25] [TRT] [I] Total Activation Memory: 11640856\n",
      "[10/21/2023-12:25:25] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 6298, GPU 21228 (MiB)\n",
      "[10/21/2023-12:25:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 105.2s, saved as '/usr/src/ultralytics/runs/classify/train/weights/best.engine' (139.3 MB)\n",
      "\n",
      "Export complete (105.2s)\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/usr/src/ultralytics/runs/classify/train/weights/best.engine imgsz=224  \n",
      "Validate:        yolo val task=classify model=/usr/src/ultralytics/runs/classify/train/weights/best.engine imgsz=224 data=imagewoof  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-12:25:25] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[10/21/2023-12:25:25] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/usr/src/ultralytics/runs/classify/train/weights/best.engine'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f994901-7d85-4872-a902-b8fb14816d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorrt_model = YOLO('/usr/src/ultralytics/runs/classify/train/weights/best.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab411291-5093-4f28-8814-f27037c65ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA A100 80GB PCIe, 81093MiB)\n",
      "Loading /usr/src/ultralytics/runs/classify/train/weights/best.engine for TensorRT inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-12:26:23] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[10/21/2023-12:26:23] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 6297, GPU 21132 (MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain:\u001b[0m /usr/src/datasets/imagewoof/train... found 9025 images in 10 classes ✅ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-12:26:24] [TRT] [I] Loaded engine size: 139 MiB\n",
      "[10/21/2023-12:26:24] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +32, now: CPU 6447, GPU 21308 (MiB)\n",
      "[10/21/2023-12:26:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[10/21/2023-12:26:24] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 6307, GPU 21308 (MiB)\n",
      "[10/21/2023-12:26:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval:\u001b[0m /usr/src/datasets/imagewoof/val... found 3929 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /usr/src/datasets/imagewoof/val... 3929 images, 0 corrupt: 100%|██████████| 3929/3929 [00:00<?, ?it/s]\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 3929/3929 [00:26<00:00, 150.46it/s]\n",
      "                   all      0.925      0.995\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/val10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = tensorrt_model.val(data='imagewoof', imgsz=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7837cea3-e64a-4c27-919e-432842e65c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 accuracy 0.925\n",
      "Top1 accuracy 0.995\n",
      "preprocess speed 0.157 ms\n",
      "inference speed 1.445 ms\n",
      "loss speed 0.012 ms\n",
      "postprocess speed 0.012 ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Top1 accuracy {metrics.top1:.3f}')\n",
    "print(f'Top1 accuracy {metrics.top5:.3f}')\n",
    "for stage, time in metrics.speed.items():\n",
    "    print(f'{stage} speed {time:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7b126a-fb5c-4fa1-a430-0bd4b952dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39e+02 Мб\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(\"/usr/src/ultralytics/runs/classify/train/weights/best.engine\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f73ce8-d714-441e-b65a-6ecbb11c9fad",
   "metadata": {},
   "source": [
    "## OpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "645817bc-c4b1-4410-80c2-32b8845249b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CPU (Intel Xeon Gold 6248 2.50GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/usr/src/ultralytics/runs/classify/train/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 10) (69.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.8s, saved as '/usr/src/ultralytics/runs/classify/train/weights/best.onnx' (138.1 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['openvino-dev>=2023.0'] not found, attempting AutoUpdate...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openvino-dev>=2023.0 in /opt/conda/lib/python3.10/site-packages (2023.0.2)\n",
      "Requirement already satisfied: addict>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (2.4.0)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (0.7.1)\n",
      "Requirement already satisfied: jstyleson>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (0.0.2)\n",
      "Requirement already satisfied: networkx<=2.8.8 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (2.8.4)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (1.23.5)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (4.8.0.76)\n",
      "Requirement already satisfied: openvino-telemetry>=2022.1.0 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (2023.1.1)\n",
      "Requirement already satisfied: pillow>=8.1.2 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (6.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (2.31.0)\n",
      "Requirement already satisfied: texttable>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (1.6.7)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (4.65.0)\n",
      "Requirement already satisfied: openvino==2023.0.2 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (2023.0.2)\n",
      "Requirement already satisfied: scipy<1.11,>=1.8 in /opt/conda/lib/python3.10/site-packages (from openvino-dev>=2023.0) (1.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2023.5.7)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 2.2s, installed 1 package: ['openvino-dev>=2023.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.0.2-11065-e662b1a3301-releases/2023/0...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success ✅ 3.7s, saved as '/usr/src/ultralytics/runs/classify/train/weights/best_openvino_model/' (138.2 MB)\n",
      "\n",
      "Export complete (7.1s)\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/usr/src/ultralytics/runs/classify/train/weights/best_openvino_model imgsz=224  \n",
      "Validate:        yolo val task=classify model=/usr/src/ultralytics/runs/classify/train/weights/best_openvino_model imgsz=224 data=imagewoof  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/usr/src/ultralytics/runs/classify/train/weights/best_openvino_model'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"openvino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00379411-2a69-48fc-97c6-4f80870546a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_model = YOLO('/usr/src/ultralytics/runs/classify/train/weights/best_openvino_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf474de1-fb15-4492-9c07-e8dc20e1fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA A100 80GB PCIe, 81093MiB)\n",
      "Loading /usr/src/ultralytics/runs/classify/train/weights/best_openvino_model for OpenVINO inference...\n",
      "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /usr/src/datasets/imagewoof/train... found 9025 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /usr/src/datasets/imagewoof/val... found 3929 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /usr/src/datasets/imagewoof/val... 3929 images, 0 corrupt: 100%|██████████| 3929/3929 [00:00<?, ?it/s]\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 3929/3929 [01:54<00:00, 34.17it/s]\n",
      "                   all      0.925      0.995\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/classify/val11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = openvino_model.val(data='imagewoof', imgsz=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3daf74eb-507d-43da-b9f2-4d9278b964f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 accuracy 0.925\n",
      "Top1 accuracy 0.995\n",
      "preprocess speed 0.032 ms\n",
      "inference speed 23.204 ms\n",
      "loss speed 0.014 ms\n",
      "postprocess speed 0.013 ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Top1 accuracy {metrics.top1:.3f}')\n",
    "print(f'Top1 accuracy {metrics.top5:.3f}')\n",
    "for stage, time in metrics.speed.items():\n",
    "    print(f'{stage} speed {time:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37c7ad38-285f-4e72-aa8d-90ea272b4722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38e+02 Мб\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(\"/usr/src/ultralytics/runs/classify/train/weights/best_openvino_model/best.bin\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0836cfb-ef7b-4cfc-813b-5385bd05cf70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
