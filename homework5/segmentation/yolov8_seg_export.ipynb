{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA A10, 24074MiB)\n",
      "Setup complete ✅ (12 CPUs, 31.1 GB RAM, 297.4/913.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "import shutil\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Измерим параметры на ГПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA A10, 24074MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/datasets/ms_coco_val_2017/val/labels.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [00:26<00:00, 11.93it/s]\n",
      "                   all       5000      36335      0.692      0.555      0.609      0.445      0.683      0.536       0.58      0.371\n",
      "                person       5000      10777      0.801      0.712      0.797      0.575      0.796      0.694      0.774      0.465\n",
      "               bicycle       5000        314       0.75      0.481      0.574      0.337      0.666      0.411      0.462      0.194\n",
      "                   car       5000       1918      0.717      0.588      0.652      0.443      0.704      0.564      0.616      0.353\n",
      "            motorcycle       5000        367      0.785      0.662      0.747      0.481      0.761      0.624        0.7      0.367\n",
      "              airplane       5000        143      0.808      0.846      0.915      0.753        0.8      0.832       0.89      0.577\n",
      "                   bus       5000        283      0.826      0.736      0.825      0.693      0.812      0.717      0.808      0.629\n",
      "                 train       5000        190      0.847      0.853        0.9      0.703      0.841      0.837      0.875       0.67\n",
      "                 truck       5000        414      0.595      0.473      0.545      0.382      0.576       0.44      0.498      0.326\n",
      "                  boat       5000        424      0.658      0.396      0.496      0.285      0.683      0.396      0.492      0.229\n",
      "         traffic light       5000        634      0.705      0.434      0.511      0.271      0.678      0.402       0.46      0.204\n",
      "          fire hydrant       5000        101      0.898      0.782      0.864      0.705      0.896      0.772      0.839       0.63\n",
      "             stop sign       5000         75      0.705      0.667      0.742       0.67       0.71      0.667      0.737      0.618\n",
      "         parking meter       5000         60      0.786      0.583      0.648      0.484      0.815      0.583      0.637       0.46\n",
      "                 bench       5000        411      0.601      0.344       0.38      0.266      0.582      0.321      0.343       0.18\n",
      "                  bird       5000        427      0.635      0.471      0.519      0.356      0.625      0.447      0.485      0.291\n",
      "                   cat       5000        202      0.836      0.861      0.901      0.724      0.847      0.866      0.913      0.701\n",
      "                   dog       5000        218      0.792      0.784      0.809       0.68      0.803       0.78      0.807      0.622\n",
      "                 horse       5000        272        0.8       0.75      0.802      0.627      0.791      0.737      0.783      0.462\n",
      "                 sheep       5000        354      0.716      0.751      0.754      0.561      0.701      0.722      0.731       0.47\n",
      "                   cow       5000        372      0.783       0.72      0.791      0.592      0.754      0.684      0.735      0.458\n",
      "              elephant       5000        252       0.77      0.885      0.849      0.665      0.784      0.889      0.859      0.591\n",
      "                  bear       5000         71      0.883      0.859      0.875      0.739      0.872      0.845      0.855      0.689\n",
      "                 zebra       5000        266      0.826      0.846      0.916      0.714       0.84      0.853      0.904       0.62\n",
      "               giraffe       5000        232       0.91      0.884       0.92      0.738      0.919      0.883      0.903      0.601\n",
      "              backpack       5000        371      0.556      0.278      0.325      0.185      0.561      0.264      0.298      0.157\n",
      "              umbrella       5000        407      0.682       0.59      0.628      0.447      0.712        0.6      0.647      0.442\n",
      "               handbag       5000        540      0.569      0.239      0.294      0.165      0.557      0.226      0.289      0.138\n",
      "                   tie       5000        252      0.762      0.482      0.561      0.367      0.732      0.456      0.523       0.31\n",
      "              suitcase       5000        299      0.674      0.538      0.626      0.435      0.695      0.534      0.616       0.41\n",
      "               frisbee       5000        115      0.839      0.815      0.869      0.685       0.82      0.783      0.846      0.586\n",
      "                  skis       5000        241      0.637      0.369      0.454      0.255      0.493      0.266      0.305     0.0826\n",
      "             snowboard       5000         69      0.592      0.442      0.513      0.375      0.588       0.42      0.463      0.253\n",
      "           sports ball       5000        260      0.742      0.535      0.594      0.431      0.696      0.488      0.526       0.28\n",
      "                  kite       5000        327      0.673      0.578      0.638      0.444       0.62      0.523      0.554      0.302\n",
      "          baseball bat       5000        145      0.636       0.51      0.531      0.336      0.643       0.51       0.53      0.256\n",
      "        baseball glove       5000        148      0.772      0.554       0.62      0.378      0.797      0.568      0.621      0.363\n",
      "            skateboard       5000        179      0.822      0.774       0.79      0.559      0.783      0.732      0.747      0.387\n",
      "             surfboard       5000        267      0.787      0.582      0.647      0.417      0.759      0.543      0.609      0.344\n",
      "         tennis racket       5000        225      0.803      0.729      0.816      0.552      0.818      0.733      0.802      0.536\n",
      "                bottle       5000       1013      0.678      0.501      0.558      0.382      0.666      0.477      0.525      0.325\n",
      "            wine glass       5000        341      0.693      0.466      0.527      0.345      0.674      0.443      0.493      0.274\n",
      "                   cup       5000        895      0.634      0.508       0.57      0.422      0.625      0.488      0.545      0.372\n",
      "                  fork       5000        215      0.666      0.447      0.535      0.379       0.63      0.413      0.443      0.213\n",
      "                 knife       5000        325      0.512      0.264      0.298      0.193       0.48      0.243      0.264      0.131\n",
      "                 spoon       5000        253       0.45      0.249      0.283      0.188      0.507      0.264      0.279      0.133\n",
      "                  bowl       5000        623      0.629      0.553      0.587      0.446      0.597      0.512      0.518      0.316\n",
      "                banana       5000        370      0.541      0.321      0.387      0.258      0.526      0.308      0.359      0.214\n",
      "                 apple       5000        236       0.47      0.305      0.304      0.216      0.475      0.297      0.297      0.201\n",
      "              sandwich       5000        177      0.567      0.486      0.526      0.393      0.544      0.446      0.453       0.34\n",
      "                orange       5000        285       0.45      0.361      0.376      0.292      0.458      0.358      0.367      0.262\n",
      "              broccoli       5000        312      0.541      0.366      0.435      0.251      0.584      0.375      0.444      0.233\n",
      "                carrot       5000        365      0.447      0.342      0.323      0.211      0.475      0.345      0.338      0.183\n",
      "               hot dog       5000        125       0.76      0.432       0.53      0.404      0.686      0.385      0.428      0.294\n",
      "                 pizza       5000        284      0.735      0.687      0.739      0.571      0.746       0.68      0.721      0.524\n",
      "                 donut       5000        328      0.645      0.512      0.578      0.458      0.655      0.515      0.573      0.431\n",
      "                  cake       5000        310      0.626      0.546      0.578      0.387      0.614      0.529      0.558      0.363\n",
      "                 chair       5000       1771      0.653       0.42      0.501       0.33      0.623      0.385      0.442       0.21\n",
      "                 couch       5000        261      0.613      0.596       0.65      0.496      0.597      0.571      0.589      0.389\n",
      "          potted plant       5000        342      0.547       0.46      0.495      0.303      0.518      0.421      0.442      0.208\n",
      "                   bed       5000        163      0.614       0.62      0.635      0.461       0.57      0.564      0.547      0.356\n",
      "          dining table       5000        695      0.577      0.447      0.476      0.322       0.47       0.35      0.328      0.138\n",
      "                toilet       5000        179      0.778      0.765      0.818      0.656      0.804      0.779      0.825      0.607\n",
      "                    tv       5000        288      0.768      0.702      0.757      0.587      0.771      0.694      0.765      0.545\n",
      "                laptop       5000        231      0.764      0.732      0.777      0.656      0.729      0.693      0.694      0.462\n",
      "                 mouse       5000        106      0.767      0.764      0.809      0.615      0.781      0.764        0.8      0.548\n",
      "                remote       5000        283      0.635      0.419      0.492      0.305      0.651      0.413      0.493      0.242\n",
      "              keyboard       5000        153      0.685      0.625      0.717      0.554      0.693      0.621      0.718      0.515\n",
      "            cell phone       5000        262      0.609      0.485      0.541       0.37      0.604      0.462      0.504      0.322\n",
      "             microwave       5000         55      0.702      0.685      0.755      0.599      0.693      0.636      0.739      0.554\n",
      "                  oven       5000        143      0.644      0.503      0.584      0.422       0.61      0.471       0.54      0.348\n",
      "               toaster       5000          9       0.79      0.422      0.523      0.403      0.783      0.406      0.523      0.406\n",
      "                  sink       5000        225      0.638      0.582      0.607      0.417      0.671      0.591      0.643      0.382\n",
      "          refrigerator       5000        126      0.748      0.659      0.753      0.619      0.771      0.669      0.761      0.586\n",
      "                  book       5000       1129      0.483       0.15      0.239      0.129      0.442      0.124       0.19     0.0854\n",
      "                 clock       5000        267      0.699      0.667      0.701      0.497      0.703      0.667      0.712      0.477\n",
      "                  vase       5000        274      0.623       0.55      0.569      0.401      0.627       0.54      0.552      0.346\n",
      "              scissors       5000         36      0.728      0.361      0.397      0.334       0.74      0.361      0.393      0.215\n",
      "            teddy bear       5000        190      0.733      0.637      0.685      0.522      0.737      0.635      0.683      0.486\n",
      "            hair drier       5000         11          1          0     0.0525     0.0192          1          0     0.0533     0.0222\n",
      "            toothbrush       5000         57      0.559      0.404      0.391      0.269      0.592      0.404      0.372      0.174\n",
      "Speed: 0.1ms preprocess, 2.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "# При валлидации происходит Fusing слоев модели!\n",
    "# было 261 слой, стало 195 слоев ! \n",
    "# уменьшение слоев примерно на 25%\n",
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Измерим параметры на ЦПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/datasets/ms_coco_val_2017/val/labels.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [07:42<00:00,  1.48s/it]\n",
      "                   all       5000      36335      0.692      0.555      0.609      0.445      0.684      0.536       0.58      0.371\n",
      "                person       5000      10777      0.801      0.712      0.797      0.575      0.798      0.694      0.774      0.465\n",
      "               bicycle       5000        314      0.751      0.481      0.573      0.337      0.666      0.411      0.462      0.194\n",
      "                   car       5000       1918      0.717      0.588      0.652      0.443      0.704      0.564      0.616      0.353\n",
      "            motorcycle       5000        367      0.784      0.662      0.747      0.481      0.761      0.624        0.7      0.366\n",
      "              airplane       5000        143      0.807      0.846      0.915      0.753        0.8      0.832       0.89      0.577\n",
      "                   bus       5000        283      0.826      0.736      0.825      0.693      0.812      0.717      0.808      0.629\n",
      "                 train       5000        190      0.847      0.853        0.9      0.703      0.841      0.836      0.874       0.67\n",
      "                 truck       5000        414      0.595      0.473      0.546      0.382      0.578       0.44      0.498      0.326\n",
      "                  boat       5000        424      0.658      0.396      0.496      0.285      0.684      0.393      0.492      0.229\n",
      "         traffic light       5000        634      0.705      0.434      0.511      0.271      0.679      0.402       0.46      0.204\n",
      "          fire hydrant       5000        101      0.898      0.782      0.864      0.705      0.896      0.772      0.839       0.63\n",
      "             stop sign       5000         75      0.705      0.667      0.742       0.67       0.71      0.667      0.737      0.618\n",
      "         parking meter       5000         60      0.785      0.583      0.648      0.484      0.817      0.583       0.64      0.461\n",
      "                 bench       5000        411      0.601      0.343       0.38      0.266      0.582      0.321      0.341       0.18\n",
      "                  bird       5000        427      0.635      0.471      0.519      0.356      0.626      0.447      0.485      0.291\n",
      "                   cat       5000        202      0.836      0.861      0.901      0.724      0.847      0.866      0.913        0.7\n",
      "                   dog       5000        218       0.79      0.784      0.809       0.68      0.804       0.78      0.807      0.622\n",
      "                 horse       5000        272      0.801       0.75      0.802      0.627      0.791      0.736      0.783      0.462\n",
      "                 sheep       5000        354      0.715      0.751      0.753      0.561      0.701      0.722      0.731       0.47\n",
      "                   cow       5000        372      0.783       0.72      0.791      0.593      0.754      0.684      0.735      0.458\n",
      "              elephant       5000        252       0.77      0.885      0.849      0.665      0.785      0.889      0.859      0.591\n",
      "                  bear       5000         71      0.883      0.859      0.875       0.74      0.872      0.845      0.855      0.689\n",
      "                 zebra       5000        266      0.825      0.846      0.916      0.714       0.84      0.853      0.904       0.62\n",
      "               giraffe       5000        232       0.91      0.884       0.92      0.737      0.919      0.883      0.903      0.601\n",
      "              backpack       5000        371      0.556      0.278      0.324      0.184      0.562      0.264      0.298      0.157\n",
      "              umbrella       5000        407      0.683       0.59      0.628      0.447      0.713        0.6      0.647      0.442\n",
      "               handbag       5000        540      0.568      0.239      0.295      0.165      0.559      0.225       0.29      0.138\n",
      "                   tie       5000        252      0.762      0.482      0.561      0.367      0.731      0.452      0.524      0.311\n",
      "              suitcase       5000        299      0.674      0.538      0.626      0.435      0.695      0.533      0.616       0.41\n",
      "               frisbee       5000        115      0.839      0.814      0.869      0.685      0.821      0.783      0.846      0.586\n",
      "                  skis       5000        241      0.636      0.369      0.454      0.255      0.493      0.266      0.305     0.0825\n",
      "             snowboard       5000         69      0.592      0.442      0.514      0.375      0.591       0.42      0.463      0.253\n",
      "           sports ball       5000        260      0.741      0.535      0.594      0.431      0.696      0.488      0.526       0.28\n",
      "                  kite       5000        327      0.673      0.578      0.638      0.444      0.622      0.523      0.554      0.301\n",
      "          baseball bat       5000        145      0.636       0.51      0.531      0.337      0.643      0.509       0.53      0.256\n",
      "        baseball glove       5000        148      0.772      0.554       0.62      0.378      0.798      0.568      0.621      0.363\n",
      "            skateboard       5000        179      0.822      0.774       0.79      0.559      0.784      0.732      0.747      0.387\n",
      "             surfboard       5000        267      0.788      0.581      0.648      0.418      0.759      0.543      0.609      0.344\n",
      "         tennis racket       5000        225      0.803      0.729      0.816      0.552      0.819      0.733      0.802      0.536\n",
      "                bottle       5000       1013      0.678      0.501      0.558      0.382      0.666      0.477      0.524      0.325\n",
      "            wine glass       5000        341      0.691      0.466      0.527      0.345      0.677      0.443      0.493      0.274\n",
      "                   cup       5000        895      0.634      0.508       0.57      0.422      0.627      0.488      0.545      0.372\n",
      "                  fork       5000        215      0.666      0.447      0.535      0.379       0.63      0.412      0.443      0.213\n",
      "                 knife       5000        325      0.512      0.264      0.298      0.193      0.482      0.243      0.264      0.131\n",
      "                 spoon       5000        253      0.448      0.249      0.282      0.188      0.499      0.259      0.276      0.133\n",
      "                  bowl       5000        623      0.629      0.553      0.586      0.446      0.598      0.512      0.518      0.316\n",
      "                banana       5000        370      0.537      0.319      0.387      0.258      0.529      0.308      0.359      0.214\n",
      "                 apple       5000        236       0.47      0.305      0.304      0.216      0.476      0.297      0.297      0.201\n",
      "              sandwich       5000        177      0.567      0.486      0.525      0.393      0.545      0.446      0.452       0.34\n",
      "                orange       5000        285       0.45      0.361      0.377      0.292      0.459      0.358      0.367      0.263\n",
      "              broccoli       5000        312      0.541      0.365      0.435      0.252      0.585      0.375      0.443      0.233\n",
      "                carrot       5000        365      0.449      0.342      0.323      0.211      0.476      0.345      0.339      0.184\n",
      "               hot dog       5000        125      0.757      0.432       0.53      0.405      0.686      0.384      0.428      0.294\n",
      "                 pizza       5000        284      0.735      0.687      0.739      0.571      0.749       0.68      0.722      0.524\n",
      "                 donut       5000        328      0.645      0.512      0.578      0.458      0.655      0.514      0.573      0.431\n",
      "                  cake       5000        310      0.626      0.546      0.578      0.387      0.614      0.529      0.558      0.363\n",
      "                 chair       5000       1771      0.653       0.42      0.501       0.33      0.625      0.385      0.442       0.21\n",
      "                 couch       5000        261      0.613      0.596       0.65      0.496      0.598      0.571      0.589      0.389\n",
      "          potted plant       5000        342      0.547      0.459      0.495      0.303      0.518      0.421      0.442      0.208\n",
      "                   bed       5000        163      0.614       0.62      0.635      0.462      0.571      0.564      0.547      0.356\n",
      "          dining table       5000        695      0.576      0.447      0.476      0.322      0.471       0.35      0.328      0.138\n",
      "                toilet       5000        179      0.778      0.765      0.818      0.656      0.804      0.778      0.825      0.607\n",
      "                    tv       5000        288      0.768      0.702      0.758      0.588      0.772      0.694      0.765      0.545\n",
      "                laptop       5000        231      0.764      0.732      0.777      0.656       0.73      0.693      0.694      0.461\n",
      "                 mouse       5000        106      0.767      0.764      0.809      0.615      0.781      0.764        0.8      0.548\n",
      "                remote       5000        283      0.635      0.418      0.492      0.305      0.651      0.413      0.494      0.242\n",
      "              keyboard       5000        153      0.685      0.625      0.717      0.554      0.693      0.621      0.718      0.515\n",
      "            cell phone       5000        262      0.609      0.485      0.541       0.37      0.605      0.462      0.505      0.322\n",
      "             microwave       5000         55      0.701      0.683      0.756      0.599      0.702      0.644      0.739      0.554\n",
      "                  oven       5000        143      0.643      0.503      0.584      0.422       0.61      0.471       0.54      0.348\n",
      "               toaster       5000          9       0.79      0.422      0.523      0.403      0.782      0.404      0.523      0.406\n",
      "                  sink       5000        225      0.638      0.582      0.607      0.417      0.672      0.591      0.643      0.382\n",
      "          refrigerator       5000        126      0.748      0.659      0.753      0.619      0.771      0.668      0.761      0.586\n",
      "                  book       5000       1129      0.483       0.15      0.239      0.129      0.446      0.124       0.19     0.0852\n",
      "                 clock       5000        267      0.698      0.667      0.701      0.497      0.703      0.667      0.712      0.477\n",
      "                  vase       5000        274      0.623       0.55      0.569      0.401      0.633       0.54      0.552      0.346\n",
      "              scissors       5000         36      0.727      0.361      0.397      0.334      0.741      0.361      0.393      0.215\n",
      "            teddy bear       5000        190       0.73      0.637      0.685      0.522      0.737      0.634      0.683      0.486\n",
      "            hair drier       5000         11          1          0     0.0525     0.0192          1          0     0.0533     0.0222\n",
      "            toothbrush       5000         57      0.562      0.404      0.389      0.267      0.592      0.404      0.369      0.173\n",
      "Speed: 0.6ms preprocess, 80.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask map50-95 0.371\n",
      "mask map50 0.58\n",
      "mask map75 0.396\n"
     ]
    }
   ],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.8 Мб\n"
     ]
    }
   ],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = os.path.getsize(\"yolov8s-seg.pt\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспорт моделей в различные форматы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно официальной документации и туториалу `YOLOv8` поддерживает экспорт в множество различных форматов. \n",
    "\n",
    "Export a YOLOv8 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLOv8 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
    "\n",
    "- 💡 ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n",
    "- 💡 ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n",
    "\n",
    "\n",
    "| Format                                                             | `format` Argument | Model                     | Metadata | Arguments                                           |\n",
    "|--------------------------------------------------------------------|-------------------|---------------------------|----------|-----------------------------------------------------|\n",
    "| [PyTorch](https://pytorch.org/)                                    | -                 | `yolov8n.pt`              | ✅        | -                                                   |\n",
    "| [TorchScript](https://pytorch.org/docs/stable/jit.html)            | `torchscript`     | `yolov8n.torchscript`     | ✅        | `imgsz`, `optimize`                                 |\n",
    "| [ONNX](https://onnx.ai/)                                           | `onnx`            | `yolov8n.onnx`            | ✅        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     |\n",
    "| [OpenVINO](https://docs.openvino.ai/latest/index.html)             | `openvino`        | `yolov8n_openvino_model/` | ✅        | `imgsz`, `half`                                     |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt)                  | `engine`          | `yolov8n.engine`          | ✅        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` |\n",
    "| [CoreML](https://github.com/apple/coremltools)                     | `coreml`          | `yolov8n.mlpackage`       | ✅        | `imgsz`, `half`, `int8`, `nms`                      |\n",
    "| [TF SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`     | `yolov8n_saved_model/`    | ✅        | `imgsz`, `keras`                                    |\n",
    "| [TF GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`              | `yolov8n.pb`              | ❌        | `imgsz`                                             |\n",
    "| [TF Lite](https://www.tensorflow.org/lite)                         | `tflite`          | `yolov8n.tflite`          | ✅        | `imgsz`, `half`, `int8`                             |\n",
    "| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`         | `yolov8n_edgetpu.tflite`  | ✅        | `imgsz`                                             |\n",
    "| [TF.js](https://www.tensorflow.org/js)                             | `tfjs`            | `yolov8n_web_model/`      | ✅        | `imgsz`                                             |\n",
    "| [PaddlePaddle](https://github.com/PaddlePaddle)                    | `paddle`          | `yolov8n_paddle_model/`   | ✅        | `imgsz`                                             |\n",
    "| [ncnn](https://github.com/Tencent/ncnn)                            | `ncnn`            | `yolov8n_ncnn_model/`     | ✅        | `imgsz`, `half`                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспорт в ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим чистую исходную модель\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (22.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.4s, saved as 'yolov8s-seg.onnx' (45.3 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8s-seg.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=yolov8s-seg.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s-seg.onnx'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "'yolov8s-seg.onnx' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb Ячейка 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu-server/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load a model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu-server/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m\"\u001b[39;49m\u001b[39myolov8s-seg.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/engine/model.py:97\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(model, task)\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load(model, task)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/engine/model.py:154\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpt_path\n\u001b[1;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     weights \u001b[39m=\u001b[39m checks\u001b[39m.\u001b[39;49mcheck_file(weights)\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt \u001b[39m=\u001b[39m weights, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m task \u001b[39mor\u001b[39;00m guess_model_task(weights)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/utils/checks.py:447\u001b[0m, in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, hard)\u001b[0m\n\u001b[1;32m    445\u001b[0m files \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39mstr\u001b[39m(ROOT \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39m**\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m file), recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# find file\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m files \u001b[39mand\u001b[39;00m hard:\n\u001b[0;32m--> 447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(files) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m hard:\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMultiple files match \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, specify exact path: \u001b[39m\u001b[39m{\u001b[39;00mfiles\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: 'yolov8s-seg.onnx' does not exist"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8s-seg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Измерим параметры на ГПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измерим параметры на ЦПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "Loading yolov8s-seg.onnx for ONNX Runtime inference...\n",
      "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/admin-gpu/Downloads/yolo_VIKA/homework1/segmentation/datasets/ms_coco_val_2017/val/labels.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 5000/5000 [09:02<00:00,  9.22it/s]\n",
      "                   all       5000      36335      0.692      0.552      0.606      0.444      0.686      0.531      0.577       0.37\n",
      "                person       5000      10777      0.798      0.711      0.796      0.574      0.797      0.691      0.772      0.464\n",
      "               bicycle       5000        314      0.728      0.465      0.567      0.335      0.644      0.398      0.462       0.19\n",
      "                   car       5000       1918      0.725      0.586      0.652       0.44      0.711      0.554      0.615       0.35\n",
      "            motorcycle       5000        367      0.783      0.649      0.745      0.482      0.773      0.623      0.682      0.359\n",
      "              airplane       5000        143      0.831      0.867      0.915      0.748      0.824      0.846      0.887      0.576\n",
      "                   bus       5000        283      0.844      0.756      0.833        0.7      0.842      0.742      0.819      0.634\n",
      "                 train       5000        190      0.834      0.832      0.892      0.701       0.84      0.832      0.868      0.669\n",
      "                 truck       5000        414      0.596      0.486      0.544      0.376      0.577      0.452      0.491      0.319\n",
      "                  boat       5000        424      0.671      0.413      0.513      0.287      0.691      0.396      0.506      0.231\n",
      "         traffic light       5000        634      0.705      0.431      0.505      0.272      0.668      0.394      0.453      0.201\n",
      "          fire hydrant       5000        101      0.899      0.794      0.866      0.695      0.898      0.782      0.839      0.637\n",
      "             stop sign       5000         75       0.71       0.64      0.738      0.672      0.718       0.64      0.734       0.61\n",
      "         parking meter       5000         60      0.805      0.583      0.657      0.486      0.789      0.567      0.609      0.463\n",
      "                 bench       5000        411      0.602      0.343      0.376      0.263      0.596      0.324      0.346      0.179\n",
      "                  bird       5000        427      0.627      0.457      0.516      0.353      0.619      0.438      0.481      0.286\n",
      "                   cat       5000        202      0.834      0.861      0.891      0.719      0.851      0.861      0.905      0.693\n",
      "                   dog       5000        218      0.779       0.78      0.801      0.676      0.795      0.775      0.801      0.616\n",
      "                 horse       5000        272      0.808      0.754      0.808      0.632      0.801      0.739      0.792      0.465\n",
      "                 sheep       5000        354      0.708      0.732      0.764      0.563      0.706      0.712      0.731      0.468\n",
      "                   cow       5000        372      0.771      0.722       0.78      0.587      0.744      0.687      0.727      0.453\n",
      "              elephant       5000        252      0.755      0.885      0.851      0.673      0.772      0.885      0.861      0.591\n",
      "                  bear       5000         71       0.84      0.859      0.857      0.735      0.847      0.855      0.857       0.69\n",
      "                 zebra       5000        266      0.808      0.857      0.917      0.719      0.821      0.853      0.906      0.618\n",
      "               giraffe       5000        232      0.888      0.875      0.921      0.733      0.899      0.878      0.902      0.602\n",
      "              backpack       5000        371      0.563       0.27      0.326      0.187      0.553       0.25        0.3      0.161\n",
      "              umbrella       5000        407      0.684      0.585      0.621      0.443      0.715      0.592      0.635      0.432\n",
      "               handbag       5000        540      0.542      0.224      0.289      0.163      0.565      0.219      0.283      0.137\n",
      "                   tie       5000        252      0.787      0.496      0.573      0.375      0.761      0.464      0.528      0.318\n",
      "              suitcase       5000        299      0.662      0.515      0.617      0.436      0.677      0.505      0.604      0.406\n",
      "               frisbee       5000        115      0.834      0.817      0.872      0.685      0.832      0.809      0.859      0.598\n",
      "                  skis       5000        241      0.667      0.374      0.443      0.257      0.512       0.27      0.302     0.0825\n",
      "             snowboard       5000         69      0.633       0.45      0.517      0.393      0.632       0.42      0.474      0.257\n",
      "           sports ball       5000        260      0.745      0.515      0.575      0.421      0.699      0.469       0.51      0.272\n",
      "                  kite       5000        327      0.662      0.575      0.629      0.441      0.608      0.517      0.554      0.304\n",
      "          baseball bat       5000        145      0.686      0.538      0.537      0.337      0.678      0.517      0.518      0.252\n",
      "        baseball glove       5000        148      0.757      0.561      0.607      0.376      0.779      0.554      0.602      0.356\n",
      "            skateboard       5000        179      0.793      0.771      0.785      0.559      0.752      0.715      0.732      0.388\n",
      "             surfboard       5000        267      0.779      0.577      0.638      0.416      0.755      0.543      0.599      0.336\n",
      "         tennis racket       5000        225      0.784      0.724      0.799      0.551      0.809      0.734      0.799      0.531\n",
      "                bottle       5000       1013      0.663      0.491      0.554       0.38      0.663      0.467      0.525      0.324\n",
      "            wine glass       5000        341      0.691      0.452       0.52      0.345      0.669      0.419      0.473      0.268\n",
      "                   cup       5000        895      0.633        0.5      0.571      0.424      0.632      0.487      0.545      0.369\n",
      "                  fork       5000        215      0.653      0.437      0.531       0.37      0.596      0.377      0.429      0.205\n",
      "                 knife       5000        325      0.557      0.268      0.301      0.197      0.525      0.228      0.266      0.135\n",
      "                 spoon       5000        253      0.486      0.265      0.276      0.182      0.511      0.273      0.268      0.127\n",
      "                  bowl       5000        623      0.617      0.541      0.585      0.445      0.604      0.506      0.528      0.321\n",
      "                banana       5000        370      0.545      0.318      0.395      0.263      0.537      0.297      0.369       0.22\n",
      "                 apple       5000        236      0.478       0.28      0.294      0.212      0.487      0.271      0.285      0.193\n",
      "              sandwich       5000        177      0.566      0.486      0.512       0.39      0.538      0.435      0.435      0.326\n",
      "                orange       5000        285      0.462      0.353      0.364      0.279      0.462      0.331      0.354      0.255\n",
      "              broccoli       5000        312      0.577      0.385      0.437      0.256       0.59      0.369      0.445      0.233\n",
      "                carrot       5000        365      0.483       0.34      0.326      0.211      0.504      0.332      0.343      0.182\n",
      "               hot dog       5000        125      0.774      0.432      0.537      0.408      0.695      0.376      0.435      0.294\n",
      "                 pizza       5000        284      0.755      0.687      0.738      0.572       0.77      0.665      0.717      0.524\n",
      "                 donut       5000        328      0.652      0.503       0.58      0.464      0.664      0.488      0.579      0.431\n",
      "                  cake       5000        310      0.658      0.559      0.587      0.388      0.647      0.535      0.564      0.358\n",
      "                 chair       5000       1771      0.649      0.418      0.497      0.327      0.624      0.381      0.436      0.208\n",
      "                 couch       5000        261      0.632      0.598       0.64      0.488      0.612      0.563       0.58      0.387\n",
      "          potted plant       5000        342      0.563      0.465      0.475      0.291      0.547      0.427      0.432      0.198\n",
      "                   bed       5000        163      0.631      0.626      0.615      0.458        0.6      0.571      0.544      0.363\n",
      "          dining table       5000        695      0.585      0.433      0.471      0.323      0.503      0.351      0.331      0.137\n",
      "                toilet       5000        179      0.791      0.793      0.832      0.669      0.802      0.793      0.832      0.612\n",
      "                    tv       5000        288      0.736      0.705      0.755      0.587      0.759      0.698      0.759      0.548\n",
      "                laptop       5000        231      0.726      0.721      0.763      0.651      0.692      0.675      0.679      0.461\n",
      "                 mouse       5000        106      0.821      0.764      0.806      0.608      0.838      0.764      0.797      0.549\n",
      "                remote       5000        283      0.643      0.417      0.495      0.301      0.665      0.407      0.485      0.237\n",
      "              keyboard       5000        153       0.69      0.627      0.721      0.562      0.713      0.614      0.715       0.52\n",
      "            cell phone       5000        262      0.595      0.477      0.531      0.368      0.569      0.439      0.497      0.319\n",
      "             microwave       5000         55      0.685      0.674      0.763      0.606      0.711      0.673      0.749      0.562\n",
      "                  oven       5000        143      0.636      0.524      0.588      0.414      0.618      0.503      0.544      0.342\n",
      "               toaster       5000          9      0.633      0.333      0.524      0.396      0.663      0.333      0.524        0.4\n",
      "                  sink       5000        225      0.661      0.582      0.597      0.413      0.693      0.587      0.633      0.379\n",
      "          refrigerator       5000        126      0.765      0.667      0.741      0.617      0.776      0.667      0.748      0.584\n",
      "                  book       5000       1129      0.502      0.145      0.229      0.126      0.462      0.116      0.184     0.0818\n",
      "                 clock       5000        267      0.713      0.671      0.701      0.497      0.731      0.674      0.723      0.471\n",
      "                  vase       5000        274      0.622      0.547      0.572      0.401      0.632      0.515      0.554      0.349\n",
      "              scissors       5000         36      0.667      0.361      0.414      0.349      0.675      0.361      0.409      0.218\n",
      "            teddy bear       5000        190      0.745      0.632      0.685      0.524      0.738      0.622      0.679      0.486\n",
      "            hair drier       5000         11          1          0     0.0272    0.00905          1          0     0.0319     0.0119\n",
      "            toothbrush       5000         57      0.527      0.368      0.384      0.284      0.611      0.421      0.396      0.186\n",
      "Speed: 0.4ms preprocess, 90.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask map50-95 0.37\n",
      "mask map50 0.577\n",
      "mask map75 0.395\n"
     ]
    }
   ],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.3 Мб\n"
     ]
    }
   ],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = os.path.getsize(\"yolov8s-seg.onnx\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"yolov8s-seg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим чистую исходную модель\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (22.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.0s, saved as 'yolov8s-seg.onnx' (45.2 MB)\n",
      "\n",
      "Export complete (2.5s)\n",
      "Results saved to \u001b[1m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8s-seg.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=yolov8s-seg.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s-seg.onnx'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"onnx\", simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8s-seg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измерим параметры на ЦПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "Loading yolov8s-seg.onnx for ONNX Runtime inference...\n",
      "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/datasets/ms_coco_val_2017/val/labels.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 16/5000 [00:01<09:05,  9.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb Ячейка 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu-server/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mval(data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mms_coco_val_2017.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, imgsz\u001b[39m=\u001b[39;49m\u001b[39m640\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/engine/model.py:276\u001b[0m, in \u001b[0;36mModel.val\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverrides, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m}  \u001b[39m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    275\u001b[0m validator \u001b[39m=\u001b[39m (validator \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_smart_load(\u001b[39m'\u001b[39m\u001b[39mvalidator\u001b[39m\u001b[39m'\u001b[39m))(args\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m--> 276\u001b[0m validator(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\n\u001b[1;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39mmetrics\n\u001b[1;32m    278\u001b[0m \u001b[39mreturn\u001b[39;00m validator\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/engine/validator.py:179\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mwith\u001b[39;00m dt[\u001b[39m3\u001b[39m]:\n\u001b[1;32m    177\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(preds)\n\u001b[0;32m--> 179\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_metrics(preds, batch)\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mplots \u001b[39mand\u001b[39;00m batch_i \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_val_samples(batch, batch_i)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/models/yolo/segment/val.py:96\u001b[0m, in \u001b[0;36mSegmentationValidator.update_metrics\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m     94\u001b[0m midx \u001b[39m=\u001b[39m [si] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moverlap_mask \u001b[39melse\u001b[39;00m idx\n\u001b[1;32m     95\u001b[0m gt_masks \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m'\u001b[39m][midx]\n\u001b[0;32m---> 96\u001b[0m pred_masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(proto, pred[:, \u001b[39m6\u001b[39;49m:], pred[:, :\u001b[39m4\u001b[39;49m], shape\u001b[39m=\u001b[39;49mbatch[\u001b[39m'\u001b[39;49m\u001b[39mimg\u001b[39;49m\u001b[39m'\u001b[39;49m][si]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m:])\n\u001b[1;32m     98\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msingle_cls:\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/utils/ops.py:665\u001b[0m, in \u001b[0;36mprocess_mask\u001b[0;34m(protos, masks_in, bboxes, shape, upsample)\u001b[0m\n\u001b[1;32m    662\u001b[0m downsampled_bboxes[:, \u001b[39m3\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m mh \u001b[39m/\u001b[39m ih\n\u001b[1;32m    663\u001b[0m downsampled_bboxes[:, \u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m mh \u001b[39m/\u001b[39m ih\n\u001b[0;32m--> 665\u001b[0m masks \u001b[39m=\u001b[39m crop_mask(masks, downsampled_bboxes)  \u001b[39m# CHW\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m upsample:\n\u001b[1;32m    667\u001b[0m     masks \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(masks[\u001b[39mNone\u001b[39;00m], shape, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m, align_corners\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m]  \u001b[39m# CHW\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = os.path.getsize(\"yolov8s-seg.onnx\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"yolov8s-seg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX simplify half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим чистую исходную модель\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "WARNING ⚠️ half=True only compatible with GPU export, i.e. use device=0\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (22.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.0s, saved as 'yolov8s-seg.onnx' (45.2 MB)\n",
      "\n",
      "Export complete (2.3s)\n",
      "Results saved to \u001b[1m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8s-seg.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=yolov8s-seg.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s-seg.onnx'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"onnx\", simplify=True, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8s-seg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измерим параметры на ЦПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = os.path.getsize(\"yolov8s-seg.onnx\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"yolov8s-seg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспорт в TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT Simplify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT Simplify Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим чистую исходную модель\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA A10, 24074MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (22.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.8s, saved as 'yolov8s-seg.onnx' (45.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.6.1...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 116, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(1, 32, 160, 160) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolov8s-seg.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/22/2023-20:09:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +349, GPU +0, now: CPU 5137, GPU 12330 (MiB)\n",
      "[10/22/2023-20:09:05] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1218, GPU +268, now: CPU 6431, GPU 12598 (MiB)\n",
      "[10/22/2023-20:09:05] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[10/22/2023-20:09:05] [TRT] [I] ----------------------------------------------------------------\n",
      "[10/22/2023-20:09:05] [TRT] [I] Input filename:   yolov8s-seg.onnx\n",
      "[10/22/2023-20:09:05] [TRT] [I] ONNX IR version:  0.0.8\n",
      "[10/22/2023-20:09:05] [TRT] [I] Opset version:    17\n",
      "[10/22/2023-20:09:05] [TRT] [I] Producer name:    pytorch\n",
      "[10/22/2023-20:09:05] [TRT] [I] Producer version: 2.1.0\n",
      "[10/22/2023-20:09:05] [TRT] [I] Domain:           \n",
      "[10/22/2023-20:09:05] [TRT] [I] Model version:    0\n",
      "[10/22/2023-20:09:05] [TRT] [I] Doc string:       \n",
      "[10/22/2023-20:09:05] [TRT] [I] ----------------------------------------------------------------\n",
      "[10/22/2023-20:09:05] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[10/22/2023-20:09:05] [TRT] [I] Graph optimization time: 0.0163062 seconds.\n",
      "[10/22/2023-20:09:05] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/22/2023-20:10:30] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
      "[10/22/2023-20:10:30] [TRT] [I] Total Host Persistent Memory: 394064\n",
      "[10/22/2023-20:10:30] [TRT] [I] Total Device Persistent Memory: 116224\n",
      "[10/22/2023-20:10:30] [TRT] [I] Total Scratch Memory: 4608\n",
      "[10/22/2023-20:10:30] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 15 MiB, GPU 261 MiB\n",
      "[10/22/2023-20:10:30] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 208 steps to complete.\n",
      "[10/22/2023-20:10:30] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 9.61635ms to assign 10 blocks to 208 nodes requiring 40966144 bytes.\n",
      "[10/22/2023-20:10:30] [TRT] [I] Total Activation Memory: 40964608\n",
      "[10/22/2023-20:10:30] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +7, GPU +52, now: CPU 7, GPU 52 (MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 90.6s, saved as 'yolov8s-seg.engine' (54.6 MB)\n",
      "\n",
      "Export complete (90.8s)\n",
      "Results saved to \u001b[1m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8s-seg.engine imgsz=640  \n",
      "Validate:        yolo val task=segment model=yolov8s-seg.engine imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s-seg.engine'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"engine\", simplify=True, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8s-seg.engine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измерим параметры на ГПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA A10, 24074MiB)\n",
      "Loading yolov8s-seg.engine for TensorRT inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/22/2023-20:10:31] [TRT] [I] Loaded engine size: 54 MiB\n",
      "[10/22/2023-20:10:31] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +51, now: CPU 0, GPU 51 (MiB)\n",
      "[10/22/2023-20:10:31] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +39, now: CPU 0, GPU 90 (MiB)\n",
      "[10/22/2023-20:10:31] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/datasets/ms_coco_val_2017/val/labels.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  20%|█▉        | 981/5000 [00:10<00:44, 90.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb Ячейка 47\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu-server/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation/yolov8_seg_export.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mval(data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mms_coco_val_2017.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, imgsz\u001b[39m=\u001b[39;49m\u001b[39m640\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/engine/model.py:276\u001b[0m, in \u001b[0;36mModel.val\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverrides, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m}  \u001b[39m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    275\u001b[0m validator \u001b[39m=\u001b[39m (validator \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_smart_load(\u001b[39m'\u001b[39m\u001b[39mvalidator\u001b[39m\u001b[39m'\u001b[39m))(args\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m--> 276\u001b[0m validator(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\n\u001b[1;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39mmetrics\n\u001b[1;32m    278\u001b[0m \u001b[39mreturn\u001b[39;00m validator\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/engine/validator.py:159\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_metrics(de_parallel(model))\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjdict \u001b[39m=\u001b[39m []  \u001b[39m# empty before each val\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[39mfor\u001b[39;00m batch_i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(bar):\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_val_batch_start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_i \u001b[39m=\u001b[39m batch_i\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/data/build.py:42\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/data/base.py:248\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m    247\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_image_and_label(index))\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/data/base.py:254\u001b[0m, in \u001b[0;36mBaseDataset.get_image_and_label\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    252\u001b[0m label \u001b[39m=\u001b[39m deepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[index])  \u001b[39m# requires deepcopy() https://github.com/ultralytics/ultralytics/pull/1948\u001b[39;00m\n\u001b[1;32m    253\u001b[0m label\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# shape is for rect, remove it\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m label[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m], label[\u001b[39m'\u001b[39m\u001b[39mori_shape\u001b[39m\u001b[39m'\u001b[39m], label[\u001b[39m'\u001b[39m\u001b[39mresized_shape\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_image(index)\n\u001b[1;32m    255\u001b[0m label[\u001b[39m'\u001b[39m\u001b[39mratio_pad\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (label[\u001b[39m'\u001b[39m\u001b[39mresized_shape\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m label[\u001b[39m'\u001b[39m\u001b[39mori_shape\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    256\u001b[0m                       label[\u001b[39m'\u001b[39m\u001b[39mresized_shape\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m label[\u001b[39m'\u001b[39m\u001b[39mori_shape\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m])  \u001b[39m# for evaluation\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrect:\n",
      "File \u001b[0;32m~/miniconda3/envs/hw5/lib/python3.10/site-packages/ultralytics/data/base.py:156\u001b[0m, in \u001b[0;36mBaseDataset.load_image\u001b[0;34m(self, i, rect_mode)\u001b[0m\n\u001b[1;32m    154\u001b[0m         im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(f)  \u001b[39m# BGR\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# read image\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(f)  \u001b[39m# BGR\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m im \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mImage Not Found \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask map50-95 0.37\n",
      "mask map50 0.577\n",
      "mask map75 0.395\n"
     ]
    }
   ],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.7 Мб\n"
     ]
    }
   ],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = os.path.getsize(\"yolov8s-seg.engine\") / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"yolov8s-seg.engine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспорт в OpenVino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим чистую исходную модель\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (22.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.5s, saved as 'yolov8s-seg.onnx' (45.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.1.0-12185-9e6b00e51cd-releases/2023/1...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success ✅ 0.6s, saved as 'yolov8s-seg_openvino_model/' (45.4 MB)\n",
      "\n",
      "Export complete (2.5s)\n",
      "Results saved to \u001b[1m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8s-seg_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=segment model=yolov8s-seg_openvino_model imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s-seg_openvino_model'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"openvino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8s-seg_openvino_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измерим параметры на ЦПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "Loading yolov8s-seg_openvino_model for OpenVINO inference...\n",
      "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/admin-gpu/Downloads/yolo_VIKA/homework1/segmentation/datasets/ms_coco_val_2017/val/labels.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 5000/5000 [06:13<00:00, 13.39it/s]\n",
      "                   all       5000      36335      0.692      0.552      0.606      0.444      0.686      0.531      0.577       0.37\n",
      "                person       5000      10777      0.798      0.711      0.796      0.574      0.797      0.691      0.772      0.464\n",
      "               bicycle       5000        314      0.728      0.465      0.567      0.335      0.644      0.398      0.462       0.19\n",
      "                   car       5000       1918      0.725      0.586      0.652       0.44      0.711      0.554      0.615       0.35\n",
      "            motorcycle       5000        367      0.783      0.649      0.745      0.482      0.773      0.623      0.682      0.359\n",
      "              airplane       5000        143      0.831      0.867      0.915      0.748      0.824      0.846      0.887      0.576\n",
      "                   bus       5000        283      0.844      0.756      0.833        0.7      0.842      0.742      0.819      0.634\n",
      "                 train       5000        190      0.834      0.832      0.892      0.701       0.84      0.832      0.868      0.669\n",
      "                 truck       5000        414      0.596      0.486      0.544      0.376      0.577      0.452      0.491      0.319\n",
      "                  boat       5000        424      0.671      0.413      0.513      0.287      0.691      0.396      0.506      0.231\n",
      "         traffic light       5000        634      0.705      0.431      0.505      0.272      0.668      0.394      0.453      0.201\n",
      "          fire hydrant       5000        101      0.899      0.794      0.866      0.695      0.898      0.782      0.839      0.637\n",
      "             stop sign       5000         75       0.71       0.64      0.738      0.672      0.718       0.64      0.734       0.61\n",
      "         parking meter       5000         60      0.805      0.583      0.657      0.486      0.789      0.567      0.609      0.463\n",
      "                 bench       5000        411      0.602      0.343      0.376      0.263      0.596      0.324      0.346      0.179\n",
      "                  bird       5000        427      0.627      0.457      0.516      0.353      0.619      0.438      0.481      0.286\n",
      "                   cat       5000        202      0.834      0.861      0.891      0.719      0.851      0.861      0.905      0.693\n",
      "                   dog       5000        218      0.779       0.78      0.801      0.676      0.795      0.775      0.801      0.616\n",
      "                 horse       5000        272      0.808      0.754      0.808      0.632      0.801      0.739      0.792      0.465\n",
      "                 sheep       5000        354      0.708      0.732      0.764      0.563      0.706      0.712      0.731      0.468\n",
      "                   cow       5000        372      0.771      0.722       0.78      0.587      0.744      0.687      0.727      0.453\n",
      "              elephant       5000        252      0.755      0.885      0.851      0.673      0.772      0.885      0.861      0.591\n",
      "                  bear       5000         71       0.84      0.859      0.857      0.735      0.847      0.855      0.857       0.69\n",
      "                 zebra       5000        266      0.808      0.857      0.917      0.719      0.821      0.853      0.906      0.618\n",
      "               giraffe       5000        232      0.888      0.875      0.921      0.733      0.899      0.878      0.902      0.602\n",
      "              backpack       5000        371      0.563       0.27      0.326      0.187      0.553       0.25        0.3      0.161\n",
      "              umbrella       5000        407      0.684      0.585      0.621      0.443      0.715      0.592      0.635      0.432\n",
      "               handbag       5000        540      0.542      0.224      0.289      0.163      0.565      0.219      0.283      0.137\n",
      "                   tie       5000        252      0.787      0.496      0.573      0.375      0.761      0.464      0.528      0.318\n",
      "              suitcase       5000        299      0.662      0.515      0.617      0.436      0.677      0.505      0.604      0.406\n",
      "               frisbee       5000        115      0.834      0.817      0.872      0.685      0.832      0.809      0.859      0.598\n",
      "                  skis       5000        241      0.667      0.374      0.443      0.257      0.512       0.27      0.302     0.0824\n",
      "             snowboard       5000         69      0.633       0.45      0.517      0.393      0.632       0.42      0.474      0.257\n",
      "           sports ball       5000        260      0.745      0.515      0.575      0.421      0.699      0.469       0.51      0.272\n",
      "                  kite       5000        327      0.662      0.575      0.629      0.441      0.608      0.517      0.554      0.304\n",
      "          baseball bat       5000        145      0.686      0.538      0.537      0.337      0.678      0.517      0.518      0.252\n",
      "        baseball glove       5000        148      0.757      0.561      0.607      0.376      0.779      0.554      0.602      0.356\n",
      "            skateboard       5000        179      0.793      0.771      0.785      0.559      0.752      0.715      0.732      0.388\n",
      "             surfboard       5000        267      0.779      0.577      0.638      0.416      0.755      0.543      0.599      0.336\n",
      "         tennis racket       5000        225      0.784      0.724      0.799      0.551      0.809      0.734      0.799      0.531\n",
      "                bottle       5000       1013      0.663      0.491      0.554       0.38      0.663      0.467      0.525      0.324\n",
      "            wine glass       5000        341      0.691      0.452       0.52      0.345      0.669      0.419      0.473      0.268\n",
      "                   cup       5000        895      0.633        0.5      0.571      0.424      0.632      0.487      0.545      0.369\n",
      "                  fork       5000        215      0.653      0.437      0.531       0.37      0.596      0.377      0.429      0.205\n",
      "                 knife       5000        325      0.557      0.268      0.301      0.197      0.525      0.228      0.266      0.135\n",
      "                 spoon       5000        253      0.486      0.265      0.276      0.182      0.511      0.273      0.268      0.127\n",
      "                  bowl       5000        623      0.617      0.541      0.585      0.445      0.604      0.506      0.528      0.321\n",
      "                banana       5000        370      0.545      0.318      0.395      0.263      0.537      0.297      0.369       0.22\n",
      "                 apple       5000        236      0.478       0.28      0.294      0.212      0.487      0.271      0.285      0.193\n",
      "              sandwich       5000        177      0.566      0.486      0.512       0.39      0.538      0.435      0.435      0.326\n",
      "                orange       5000        285      0.462      0.353      0.364      0.279      0.462      0.331      0.354      0.255\n",
      "              broccoli       5000        312      0.577      0.385      0.437      0.256       0.59      0.369      0.445      0.233\n",
      "                carrot       5000        365      0.483       0.34      0.326      0.211      0.504      0.332      0.343      0.182\n",
      "               hot dog       5000        125      0.774      0.432      0.537      0.408      0.695      0.376      0.435      0.294\n",
      "                 pizza       5000        284      0.755      0.687      0.738      0.572       0.77      0.665      0.717      0.524\n",
      "                 donut       5000        328      0.652      0.503       0.58      0.464      0.664      0.488      0.579      0.431\n",
      "                  cake       5000        310      0.658      0.559      0.587      0.388      0.647      0.535      0.564      0.358\n",
      "                 chair       5000       1771      0.649      0.418      0.497      0.327      0.624      0.381      0.436      0.208\n",
      "                 couch       5000        261      0.632      0.598       0.64      0.488      0.612      0.563       0.58      0.387\n",
      "          potted plant       5000        342      0.563      0.465      0.475      0.291      0.547      0.427      0.432      0.198\n",
      "                   bed       5000        163      0.631      0.626      0.615      0.458        0.6      0.571      0.544      0.363\n",
      "          dining table       5000        695      0.585      0.433      0.471      0.323      0.503      0.351      0.331      0.137\n",
      "                toilet       5000        179      0.791      0.793      0.832      0.669      0.802      0.793      0.832      0.612\n",
      "                    tv       5000        288      0.736      0.705      0.755      0.587      0.759      0.698      0.759      0.548\n",
      "                laptop       5000        231      0.726      0.721      0.763      0.651      0.692      0.675      0.679      0.461\n",
      "                 mouse       5000        106      0.821      0.764      0.806      0.608      0.838      0.764      0.797      0.549\n",
      "                remote       5000        283      0.643      0.417      0.495      0.301      0.665      0.407      0.485      0.237\n",
      "              keyboard       5000        153       0.69      0.627      0.721      0.562      0.713      0.614      0.715       0.52\n",
      "            cell phone       5000        262      0.595      0.477      0.531      0.368      0.569      0.439      0.497      0.319\n",
      "             microwave       5000         55      0.685      0.674      0.763      0.606      0.711      0.673      0.749      0.562\n",
      "                  oven       5000        143      0.636      0.524      0.588      0.414      0.618      0.503      0.544      0.342\n",
      "               toaster       5000          9      0.633      0.333      0.524      0.396      0.663      0.333      0.524        0.4\n",
      "                  sink       5000        225      0.661      0.582      0.597      0.413      0.693      0.587      0.633      0.379\n",
      "          refrigerator       5000        126      0.765      0.667      0.741      0.617      0.776      0.667      0.748      0.584\n",
      "                  book       5000       1129      0.502      0.145      0.229      0.126      0.462      0.116      0.184     0.0818\n",
      "                 clock       5000        267      0.713      0.671      0.701      0.497      0.731      0.674      0.723      0.471\n",
      "                  vase       5000        274      0.622      0.547      0.572      0.401      0.632      0.515      0.554      0.349\n",
      "              scissors       5000         36      0.667      0.361      0.414      0.349      0.675      0.361      0.409      0.218\n",
      "            teddy bear       5000        190      0.745      0.632      0.685      0.524      0.738      0.622      0.679      0.486\n",
      "            hair drier       5000         11          1          0     0.0272    0.00905          1          0     0.0319     0.0119\n",
      "            toothbrush       5000         57      0.527      0.368      0.384      0.284      0.611      0.421      0.396      0.186\n",
      "Speed: 0.4ms preprocess, 60.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask map50-95 0.37\n",
      "mask map50 0.577\n",
      "mask map75 0.395\n"
     ]
    }
   ],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23e+02 Мб\n"
     ]
    }
   ],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = sum(os.path.getsize(f) for f in os.listdir('.') if os.path.isfile(f)) / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('yolov8s-seg_openvino_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVino half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим чистую исходную модель\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# build a new model from scratch\n",
    "model = YOLO(\"yolov8s-seg.yaml\")\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i5-12600)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (22.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.5s, saved as 'yolov8s-seg.onnx' (45.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.1.0-12185-9e6b00e51cd-releases/2023/1...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success ✅ 0.1s, saved as 'yolov8s-seg_openvino_model/' (22.9 MB)\n",
      "\n",
      "Export complete (2.0s)\n",
      "Results saved to \u001b[1m/home/admin-gpu/Downloads/yolo_VIKA/homework5/segmentation\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8s-seg_openvino_model imgsz=640 half \n",
      "Validate:        yolo val task=segment model=yolov8s-seg_openvino_model imgsz=640 data=coco.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s-seg_openvino_model'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"openvino\", half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8s-seg_openvino_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измерим параметры на ЦПУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val(data=\"ms_coco_val_2017.yaml\", imgsz=640, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим метрики для сегментации\n",
    "print(f\"mask map50-95 {metrics.seg.map:.3}\")\n",
    "print(f\"mask map50 {metrics.seg.map50:.3}\")\n",
    "print(f\"mask map75 {metrics.seg.map75:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23e+02 Мб\n"
     ]
    }
   ],
   "source": [
    "# оценим размер сериализованной модели\n",
    "model_size = sum(os.path.getsize(f) for f in os.listdir('.') if os.path.isfile(f)) / 1024**2\n",
    "print(f\"{model_size:.3} Мб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('yolov8s-seg_openvino_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework5-segmentation-u-9vj8JT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
