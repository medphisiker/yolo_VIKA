{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# –ú–µ—Ç–æ–¥—ã –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π"
      ],
      "metadata": {
        "id": "eSzq1iXDSvQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –õ–µ–∫—Ü–∏—è ‚Ññ1 - –í–≤–µ–¥–µ–Ω–∏–µ –≤ –∫–æ–º–ø—Ä–µ—Å—Å–∏—é –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: –í–≤–æ–¥–Ω–∞—è\n",
        "- –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º–ø—Ä–µ—Å—Å–∏—è –º–æ–¥–µ–ª–µ–π –∏ –∑–∞—á–µ–º –æ–Ω–∞ –Ω—É–∂–Ω–∞?\n",
        "- –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å\n",
        "- –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã, –∫–∞–∫ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –∫—É—Ä—Å –∏—Ç–¥\n",
        "\n",
        "## –î–ó ‚Ññ1\n",
        "–†–∞–∑–¥–µ–ª–∏—Ç—å—Å—è –Ω–∞ –∫–æ–º–∞–Ω–¥—ã –ø–æ 4 —á–µ–ª–æ–≤–µ–∫–∞ –∏ –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, —Å–¥–µ–ª–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –∑–∞–º–µ—Ä—ã –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n"
      ],
      "metadata": {
        "id": "rJFtmYoaU5Z4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ YOLOv8m-cls\n",
        "\n",
        "–ü—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
        "- —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏;\n",
        "- –≤–µ—Å —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏;\n",
        "- –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ RAM –ø–æ—Ç—Ä–µ–±–ª—è–µ–º–æ–µ –º–æ–¥–µ–ª—å—é;\n",
        "- –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞;\n",
        "- —Ü–µ–ª–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞."
      ],
      "metadata": {
        "id": "CD-90ZguVUjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞"
      ],
      "metadata": {
        "id": "3KFU7LDcw9j4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aeG0lXtugDuW"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 uninstall torch -y\n",
        "! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "YP6F5wzG6Iaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-ml-py3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isEcuN2mdqAV",
        "outputId": "616021c5-4c5c-45ce-fa1f-c79766825a16"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-ml-py3\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-ml-py3\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=34bdd40c73936ee3c312b45a13961eb0a9d5e4a951453a6bdc9542e301bed109\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "Successfully built nvidia-ml-py3\n",
            "Installing collected packages: nvidia-ml-py3\n",
            "Successfully installed nvidia-ml-py3-7.352.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.set_device(0) # Set to your desired GPU number\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wstSy5NvwIB",
        "outputId": "010b01e7-b3bb-44e7-9b9a-ca805505566b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ],
      "metadata": {
        "id": "2RRWnyXcxBBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –ó–∞–º–µ—Ä—ã RAM-before"
      ],
      "metadata": {
        "id": "2UguS6YqefVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import nvidia_smi\n",
        "info_gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(info_gpus) > 0:\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    device_count = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(device_count):\n",
        "      handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "      info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "      print(f\"Device {i}: {nvidia_smi.nvmlDeviceGetName(handle).decode()}\")\n",
        "      print(f\"Memory : {round(100*info.free/info.total,2)}% free: {info.total}(total), {info.free} (free), {info.used} (used)\")\n",
        "\n",
        "    nvidia_smi.nvmlShutdown()\n",
        "else:\n",
        "  print(\"No GPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gUmwGBSdL2-",
        "outputId": "6fa5de7c-0bfc-4dcd-b2e9-faf4540251ec"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "Memory : 82.91% free: 16106127360(total), 13353418752 (free), 2752708608 (used)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem_before = info.used"
      ],
      "metadata": {
        "id": "xqsCrvw8eWXB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –ß–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
      ],
      "metadata": {
        "id": "-VvLq7TQZ_ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a COCO-pretrained YOLOv8n model\n",
        "model = YOLO('yolov8m-cls.pt')"
      ],
      "metadata": {
        "id": "XuFuSo9O3VJp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IEmt5ojXcqO",
        "outputId": "b3b164a9-b304-42ff-9a30-e6c23db1f337"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv8m-cls summary: 141 layers, 17053336 parameters, 0 gradients\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(141, 17053336, 0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –í–µ—Å –º–æ–¥–µ–ª–∏"
      ],
      "metadata": {
        "id": "IbOBV_YkaEVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_size = 0\n",
        "for param in model.model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_NejLeXmM_",
        "outputId": "40758524-f208-4ac8-e82c-3a20d5cfa268"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 65.127MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –¶–µ–ª–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞"
      ],
      "metadata": {
        "id": "E6VsnyZfaRrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "results = model.train(data='imagenette', epochs=20, imgsz=224, device=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkUZnWr3gmGp",
        "outputId": "edab86c8-d3ad-43e4-d151-7382414e4a96"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.176 üöÄ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=imagenette, epochs=20, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenette/train... found 9469 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenette/val... found 3925 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
            "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
            "  9                  -1  1    998410  ultralytics.nn.modules.head.Classify         [768, 10]                     \n",
            "YOLOv8m-cls summary: 141 layers, 15785146 parameters, 15785146 gradients\n",
            "Transferred 228/230 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/imagenette/train... 9469 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9469/9469 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/imagenette/val... 3925 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3925/3925 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/20      1.39G     0.1485         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:48<00:00,  5.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:30<00:00,  3.98it/s]\n",
            "                   all      0.961      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/20      1.43G    0.07485         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:30<00:00,  6.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:26<00:00,  4.66it/s]\n",
            "                   all      0.926      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/20      1.41G    0.08433         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:28<00:00,  6.72it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.22it/s]\n",
            "                   all      0.925      0.994\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/20      1.44G    0.06867         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:18<00:00,  7.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:24<00:00,  5.10it/s]\n",
            "                   all      0.938      0.996\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/20      1.42G     0.0579         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:27<00:00,  6.76it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:25<00:00,  4.80it/s]\n",
            "                   all      0.937      0.996\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/20      1.42G     0.0441         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:28<00:00,  6.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:26<00:00,  4.71it/s]\n",
            "                   all      0.946      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/20      1.42G    0.03408         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:28<00:00,  6.70it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:25<00:00,  4.77it/s]\n",
            "                   all      0.947      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/20      1.43G    0.02541         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:28<00:00,  6.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:25<00:00,  4.80it/s]\n",
            "                   all      0.953      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/20      1.42G    0.02459         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:28<00:00,  6.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:25<00:00,  4.76it/s]\n",
            "                   all      0.957      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/20      1.41G     0.0202         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:24<00:00,  4.92it/s]\n",
            "                   all      0.954      0.999\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      11/20      1.44G    0.01853         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:25<00:00,  4.76it/s]\n",
            "                   all      0.956      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      12/20      1.43G     0.0126         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.16it/s]\n",
            "                   all      0.963      0.999\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      13/20      1.42G    0.01098         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.14it/s]\n",
            "                   all      0.969      0.998\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      14/20       1.4G   0.007709         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:32<00:00,  6.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.31it/s]\n",
            "                   all      0.966      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      15/20      1.42G   0.006528         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.46it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.32it/s]\n",
            "                   all      0.968      0.998\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      16/20      1.42G   0.006772         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:32<00:00,  6.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.18it/s]\n",
            "                   all      0.967      0.998\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      17/20      1.41G   0.005702         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.23it/s]\n",
            "                   all      0.968      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      18/20      1.41G   0.004438         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:31<00:00,  6.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:24<00:00,  5.12it/s]\n",
            "                   all      0.973      0.997\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      19/20       1.4G   0.003061         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:29<00:00,  6.60it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:26<00:00,  4.56it/s]\n",
            "                   all      0.974      0.998\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      20/20      1.42G   0.002846         13        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 592/592 [01:29<00:00,  6.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:26<00:00,  4.64it/s]\n",
            "                   all      0.975      0.998\n",
            "\n",
            "20 epochs completed in 0.658 hours.\n",
            "Optimizer stripped from runs/classify/train2/weights/last.pt, 31.7MB\n",
            "Optimizer stripped from runs/classify/train2/weights/best.pt, 31.7MB\n",
            "\n",
            "Validating runs/classify/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.176 üöÄ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8m-cls summary (fused): 103 layers, 15775466 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenette/train... found 9469 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenette/val... found 3925 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:25<00:00,  4.77it/s]\n",
            "                   all      0.975      0.998\n",
            "Speed: 0.2ms preprocess, 1.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()  # no arguments needed, dataset and settings remembered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFRlUZ_JaPLn",
        "outputId": "b9a1b848-e0cb-4052-b766-2389fc1baa52"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.176 üöÄ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8m-cls summary (fused): 103 layers, 15775466 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenette/train... found 9469 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenette/val... found 3925 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/imagenette/val... 3925 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3925/3925 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [00:28<00:00,  8.72it/s]\n",
            "                   all      0.975      0.998\n",
            "Speed: 0.1ms preprocess, 2.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"top1_acc:\", metrics.top1)\n",
        "print(\"top5_acc:\", metrics.top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkalMj91Jnjt",
        "outputId": "337baea3-7a2b-450b-97ed-333e7b1ce77b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top1_acc: 0.9747770428657532\n",
            "top5_acc: 0.9982165098190308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –ó–∞–º–µ—Ä—ã RAM-after"
      ],
      "metadata": {
        "id": "OGK0liUmfDcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import nvidia_smi\n",
        "info_gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(info_gpus) > 0:\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    device_count = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(device_count):\n",
        "      handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "      info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "      print(f\"Device {i}: {nvidia_smi.nvmlDeviceGetName(handle).decode()}\")\n",
        "      print(f\"Memory : {round(100*info.free/info.total,2)}% free: {info.total}(total), {info.free} (free), {info.used} (used)\")\n",
        "\n",
        "    nvidia_smi.nvmlShutdown()\n",
        "else:\n",
        "  print(\"No GPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7c185e-b2d9-43f1-c3a5-67a2444e13ba",
        "id": "tz9pxjSRfDcD"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "Memory : 80.19% free: 16106127360(total), 12915113984 (free), 3191013376 (used)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem_after = (info.used - mem_before) / 1024**2\n",
        "mem_after"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPS5Yt4TfDcE",
        "outputId": "2fdc9053-2c1a-4744-aee7-15755cdc09f6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "418.0"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S15KN6keoX2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –ò–Ω—Ñ–µ—Ä–µ–Ω—Å"
      ],
      "metadata": {
        "id": "1zDnhRX3fXhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('./content')"
      ],
      "metadata": {
        "id": "w6yJsQNCpF5G"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference with the YOLOv8n model on the 'bus.jpg' image\n",
        "results = model('train[7shard]_459.jpeg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1FbySM7gQsL",
        "outputId": "8a02b968-7cc9-4e36-826a-d6663c212402"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/train[7shard]_459.jpeg: 224x224 garbage_truck 1.00, chain_saw 0.00, golf_ball 0.00, tench 0.00, English_springer 0.00, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSZ-Kw3VqAM2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}