{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YPklMZYY9rY8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "1IKIbVsDuWEK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tynGTYW91Ep",
        "outputId": "76cb1ed3-ab0f-45ff-fcea-74dcafcf4a41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an-JiGPn9u_7",
        "outputId": "31d34399-88ec-480b-de55-8e85c75c2872"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUPnsaTQ93Jv",
        "outputId": "6a3ced40-0e32-44c1-ed5c-a76601bec16b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(DeepNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "E0N6Mftd973e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LightNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "k-ZwGDIa9_Ct"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, learning_rate, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "iHqLCvV9-Bry"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_deep = DeepNN(num_classes=10).to(device)\n",
        "train(nn_deep, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_deep = test(nn_deep, test_loader, device)\n",
        "\n",
        "nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2w6Htec-My1",
        "outputId": "35f2a101-becc-44a9-c3b8-62dd64e9a36a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3364965619943332\n",
            "Epoch 2/10, Loss: 0.8654787737085387\n",
            "Epoch 3/10, Loss: 0.6836608006521259\n",
            "Epoch 4/10, Loss: 0.5415086426088572\n",
            "Epoch 5/10, Loss: 0.42425573051280685\n",
            "Epoch 6/10, Loss: 0.3224685495847936\n",
            "Epoch 7/10, Loss: 0.23955098318550594\n",
            "Epoch 8/10, Loss: 0.1833318435703702\n",
            "Epoch 9/10, Loss: 0.14343779881858765\n",
            "Epoch 10/10, Loss: 0.12229370552560558\n",
            "Test Accuracy: 74.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "VwWzx-ti-QSS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Deep model total params:\", sum(p.numel() for p in nn_deep.parameters()))\n",
        "print(\"Light model total params:\", sum(p.numel() for p in nn_light.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1AD4SdP_i3C",
        "outputId": "840b6cd3-c31c-4890-8f5b-8462d189958e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep model total params: 1186986\n",
            "Light model total params: 267738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Norm of 1st layer of nn_light:\", torch.norm(nn_light.features[0].weight).item())\n",
        "print(\"Norm of 1st layer of new_nn_light:\", torch.norm(new_nn_light.features[0].weight).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XycU6WO7-Ter",
        "outputId": "9407f266-8b0a-41a6-ca96-c37b755fbb0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm of 1st layer of nn_light: 2.3050243854522705\n",
            "Norm of 1st layer of new_nn_light: 2.3408451080322266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(nn_light, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_light_ce = test(nn_light, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2Wf8jzZ_DaE",
        "outputId": "f0a27593-f1fb-4389-eb93-d8aabf88771b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4877664506282953\n",
            "Epoch 2/10, Loss: 1.1530771217382778\n",
            "Epoch 3/10, Loss: 1.0145730004286218\n",
            "Epoch 4/10, Loss: 0.9191851565600051\n",
            "Epoch 5/10, Loss: 0.8374220773082255\n",
            "Epoch 6/10, Loss: 0.7742109080714643\n",
            "Epoch 7/10, Loss: 0.7130406979099869\n",
            "Epoch 8/10, Loss: 0.6617929284529918\n",
            "Epoch 9/10, Loss: 0.6090308250978475\n",
            "Epoch 10/10, Loss: 0.5616080699979192\n",
            "Test Accuracy: 69.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy: {test_accuracy_light_ce:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJaY9H7p_xll",
        "outputId": "1ad62e49-fc97-44fd-9881-7946276eedd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher accuracy: 74.65%\n",
            "Student accuracy: 69.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    teacher.eval()  # Teacher set to evaluation mode\n",
        "    student.train() # Student to train mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(inputs)\n",
        "\n",
        "            # Forward pass with the student model\n",
        "            student_logits = student(inputs)\n",
        "\n",
        "            #Soften the student logits by applying softmax first and log() second\n",
        "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "\n",
        "            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
        "            soft_targets_loss = -torch.sum(soft_targets * soft_prob) / soft_prob.size()[0] * (T**2)\n",
        "\n",
        "            # Calculate the true label loss\n",
        "            label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "            # Weighted sum of the two losses\n",
        "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "id": "rjvjFwt2_5De"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(teacher=nn_deep, student=new_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd = test(new_nn_light, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF4KfM3x_6Pj",
        "outputId": "ccbe2bbd-81aa-4b5e-851b-0de8fdbb7050"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.8022243031455427\n",
            "Epoch 2/10, Loss: 2.2846382231358677\n",
            "Epoch 3/10, Loss: 2.025640567550269\n",
            "Epoch 4/10, Loss: 1.82984959377962\n",
            "Epoch 5/10, Loss: 1.6838307435555226\n",
            "Epoch 6/10, Loss: 1.576995578873188\n",
            "Epoch 7/10, Loss: 1.4885320693940458\n",
            "Epoch 8/10, Loss: 1.404069697460555\n",
            "Epoch 9/10, Loss: 1.329248496790981\n",
            "Epoch 10/10, Loss: 1.2561139263155516\n",
            "Test Accuracy: 70.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "id": "rzn26gqdA3Vs",
        "outputId": "36f7fa77-659e-47ed-fb90-56c38669b64c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher accuracy: 74.65%\n",
            "Student accuracy without teacher: 69.91%\n",
            "Student accuracy with CE + KD: 70.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rAE3crK5_9v_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}